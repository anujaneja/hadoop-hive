Follow:

http://www.thecloudavenue.com/2013/03/analyse-tweets-using-flume-hadoop-and.html

Download and Copy flume-sources-1.0-SNAPSHOT.jar  to Desktop on VM

cd /etc/flume-ng/conf/

cp flume-env.sh.template flume-env.sh

Paste this line in flume-env.sh

FLUME_CLASSPATH="/home/cloudera/Desktop/flume-sources-1.0-SNAPSHOT.jar"

create flume.conf

and paste the below given content:


TwitterAgent.sources = Twitter
TwitterAgent.channels = MemChannel
TwitterAgent.sinks = HDFS
 
TwitterAgent.sources.Twitter.type = com.cloudera.flume.source.TwitterSource
TwitterAgent.sources.Twitter.channels = MemChannel
TwitterAgent.sources.Twitter.consumerKey = i6KTTd3YYMsYJNUT9pm9UuB6v
TwitterAgent.sources.Twitter.consumerSecret = PavclGFTEm2bRBQbVlQKODl8URT2FgT9BvEZsMNyLRB88HMHxz
TwitterAgent.sources.Twitter.accessToken = 358733145-8ObOfX9eSY7fl9CAkQQoO1LLmQFsFUyye2fGxcEW
TwitterAgent.sources.Twitter.accessTokenSecret = BbA2TmQGO34Gl1oc7XBbsx99n2P1YgGbCUIuMiBq4kc5C
 
TwitterAgent.sources.Twitter.keywords = hadoop, big data, analytics, bigdata, cloudera, data science, data scientiest, business intelligence, mapreduce, data warehouse, data warehousing, mahout, hbase, nosql, newsql, businessintelligence, cloudcomputing
 
TwitterAgent.sinks.HDFS.channel = MemChannel
TwitterAgent.sinks.HDFS.type = hdfs
TwitterAgent.sinks.HDFS.hdfs.path = /user/flume/tweets/
TwitterAgent.sinks.HDFS.hdfs.fileType = DataStream
TwitterAgent.sinks.HDFS.hdfs.writeFormat = Text
TwitterAgent.sinks.HDFS.hdfs.batchSize = 1000
TwitterAgent.sinks.HDFS.hdfs.rollSize = 0
TwitterAgent.sinks.HDFS.hdfs.rollCount = 10000
 
TwitterAgent.channels.MemChannel.type = memory
TwitterAgent.channels.MemChannel.capacity = 10000
TwitterAgent.channels.MemChannel.transactionCapacity = 100



Update consumerKey,consumerSecret,accessToken,accessTokenSecret and also we can edit keywords


Now run the following command:

cd /usr/lib/flume-ng/lib

rename the following jars to <jar_name>.bak e.g. twitter4j-core-3.0.3.jar.bak

twitter4j-core-3.0.3.jar  
twitter4j-media-support-3.0.3.jar
twitter4j-stream-3.0.3.jar


flume-ng agent --conf /etc/flume-ng/conf/ -f /etc/flume-ng/conf/flume.conf -Dflume.root.logger=DEBUG,console -n TwitterAgent


Download jar from link and save it on desktop http://files.cloudera.com/samples/hive-serdes-1.0-SNAPSHOT.jar

Run the following command:

hive

ADD JAR <path to jar file>/lib/hive-serdes-1.0-SNAPSHOT.jar;


Create external table tweets:


CREATE EXTERNAL TABLE tweets (
   id BIGINT,
   created_at STRING,
   source STRING,
   favorited BOOLEAN,
   retweet_count INT,
   retweeted_status STRUCT<
      text:STRING,
      user:STRUCT<screen_name:STRING,name:STRING>>,
   entities STRUCT<
      urls:ARRAY<STRUCT<expanded_url:STRING>>,
      user_mentions:ARRAY<STRUCT<screen_name:STRING,name:STRING>>,
      hashtags:ARRAY<STRUCT<text:STRING>>>,
   text STRING,
   user STRUCT<
      screen_name:STRING,
      name:STRING,
      friends_count:INT,
      followers_count:INT,
      statuses_count:INT,
      verified:BOOLEAN,
      utc_offset:INT,
      time_zone:STRING>,
   in_reply_to_screen_name STRING
) 
ROW FORMAT SERDE 'com.cloudera.hive.serde.JSONSerDe'
LOCATION '/user/flume/tweets';



Now you can run the commands to check for data:


SELECT t.retweeted_screen_name, sum(retweets) AS total_retweets, count(*) AS tweet_count FROM (SELECT retweeted_status.user.screen_name as retweeted_screen_name, retweeted_status.text, max(retweet_count) as retweets FROM tweets GROUP BY retweeted_status.user.screen_name, retweeted_status.text) t GROUP BY t.retweeted_screen_name ORDER BY total_retweets DESC LIMIT 10;


select user.screen_name, user.followers_count c from tweets order by c desc; 













